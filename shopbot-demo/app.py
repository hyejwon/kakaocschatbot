import os
import re
import pandas as pd
import streamlit as st
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

st.set_page_config(page_title="ì‡¼í•‘ëª° CS ë¶„ë¥˜ + RAG ë°ëª¨", layout="wide")

# -----------------------------
# Utilities
# -----------------------------
CATEGORIES = ["ì£¼ë¬¸/ê²°ì œ", "ë°°ì†¡", "êµí™˜/í™˜ë¶ˆ", "ìƒí’ˆ ë¬¸ì˜", "íšŒì›/ë¡œê·¸ì¸", "ì¿ í°/í¬ì¸íŠ¸", "ê¸°íƒ€(ìƒë‹´í•„ìš”)"]

KEYWORD_RULES = {
    "êµí™˜/í™˜ë¶ˆ": [r"í™˜ë¶ˆ", r"ë°˜í’ˆ", r"êµí™˜", r"ì·¨ì†Œ", r"ì² íšŒ"],
    "ë°°ì†¡": [r"ë°°ì†¡", r"ì¶œê³ ", r"ì†¡ìž¥", r"íƒë°°", r"ì–¸ì œ ì™€", r"ë„ì°©", r"ì§€ì—°"],
    "ì£¼ë¬¸/ê²°ì œ": [r"ê²°ì œ", r"ì¹´ë“œ", r"ìŠ¹ì¸", r"ì£¼ë¬¸", r"ìž…ê¸ˆ", r"ê²°ì œ ì‹¤íŒ¨"],
    "ìƒí’ˆ ë¬¸ì˜": [r"ì‚¬ì´ì¦ˆ", r"ìž¬ê³ ", r"ìƒ‰ìƒ", r"ìŠ¤íŽ™", r"ì†Œìž¬", r"í•", r"ê¸¸ì´"],
    "íšŒì›/ë¡œê·¸ì¸": [r"ë¡œê·¸ì¸", r"ë¹„ë°€ë²ˆí˜¸", r"ì•„ì´ë””", r"ì¸ì¦", r"íšŒì›"],
    "ì¿ í°/í¬ì¸íŠ¸": [r"ì¿ í°", r"í¬ì¸íŠ¸", r"ì ë¦½", r"í• ì¸", r"í”„ë¡œëª¨ì…˜"]
}

def rule_classify(text: str):
    t = text.strip().lower()
    hits = []
    for cat, patterns in KEYWORD_RULES.items():
        score = 0
        for p in patterns:
            if re.search(p, t, re.IGNORECASE):
                score += 1
        if score > 0:
            hits.append((cat, score))
    hits.sort(key=lambda x: x[1], reverse=True)
    if not hits:
        return "ê¸°íƒ€(ìƒë‹´í•„ìš”)", 0.35, ["í‚¤ì›Œë“œ ë§¤ì¹­ ì—†ìŒ"]
    top_cat, top_score = hits[0]
    conf = min(0.55 + 0.1 * (top_score - 1), 0.85)  # ê°€ë²¼ìš´ ì‹ ë¢°ë„ ì¶”ì •
    reasons = [f"í‚¤ì›Œë“œ ë§¤ì¹­: {top_cat} ({top_score}ê°œ)"]
    return top_cat, conf, reasons

def load_kb(path: str) -> pd.DataFrame:
    if not os.path.exists(path):
        return pd.DataFrame(columns=["id", "category", "title", "content"])
    df = pd.read_csv(path)
    for col in ["id", "category", "title", "content"]:
        if col not in df.columns:
            df[col] = ""
    df = df.fillna("")
    return df

@st.cache_data(show_spinner=False)
def build_retriever(df: pd.DataFrame):
    # content + title í•©ì³ì„œ ê²€ìƒ‰ í’ˆì§ˆ ê°œì„ 
    corpus = (df["title"].astype(str) + " " + df["content"].astype(str)).tolist()
    if len(corpus) == 0:
        return None, None, corpus
    vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=6000)
    X = vectorizer.fit_transform(corpus)
    return vectorizer, X, corpus

def retrieve(df: pd.DataFrame, vectorizer, X, query: str, topk: int = 3):
    if df.empty or vectorizer is None or X is None:
        empty_df = pd.DataFrame(columns=list(df.columns) + ["score"])
        return empty_df, []
    qv = vectorizer.transform([query])
    sims = cosine_similarity(qv, X).flatten()
    idxs = sims.argsort()[::-1][:topk]
    rows = df.iloc[idxs].copy()
    rows["score"] = [float(sims[i]) for i in idxs]
    return rows, idxs

def should_fallback_internal(internal_hits: pd.DataFrame, threshold=0.18) -> bool:
    if internal_hits.empty:
        return True
    return float(internal_hits.iloc[0]["score"]) < threshold

def generate_template_answer(category: str, user_text: str, source_title: str, source_content: str, source_type: str):
    # LLM ì—†ì´ë„ ë°ëª¨ê°€ ê·¸ëŸ´ë“¯í•˜ê²Œ ë³´ì´ë„ë¡ "CS í…œí”Œë¦¿" ê¸°ë°˜ ë‹µë³€
    base = f"ë¬¸ì˜ ìœ í˜•: **{category}**\n\n"
    if source_type == "internal":
        base += "ë‚´ë¶€ ì •ì±…/FAQë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤.\n\n"
    else:
        base += "ë‚´ë¶€ ì •ì±… ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬, ì¼ë°˜ì ì¸ ê³µê°œ ì§€ì‹/ê°€ì´ë“œ ê¸°ì¤€ìœ¼ë¡œ ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤.\n\n"

    base += f"**ì°¸ê³  í•­ëª©:** {source_title}\n\n"
    base += f"- ì•ˆë‚´: {source_content}\n\n"
    # ì¹´í…Œê³ ë¦¬ë³„ ì¶”ê°€ ì§ˆë¬¸(ì‹¤ë¬´ ëŠë‚Œ)
    followups = {
        "ë°°ì†¡": "ê°€ëŠ¥í•˜ì‹œë©´ **ì£¼ë¬¸ë²ˆí˜¸**ì™€ **ìˆ˜ë ¹ìž ì„±í•¨/ì—°ë½ì²˜**ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë°°ì†¡ ìƒíƒœ í™•ì¸ì— ë„ì›€ì´ ë©ë‹ˆë‹¤.",
        "êµí™˜/í™˜ë¶ˆ": "ê°€ëŠ¥í•˜ì‹œë©´ **ì£¼ë¬¸ë²ˆí˜¸**, **ìˆ˜ë ¹ì¼**, **ìƒí’ˆ ìƒíƒœ(ë¯¸ê°œë´‰/ì‚¬ìš© ì—¬ë¶€)**ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.",
        "ì£¼ë¬¸/ê²°ì œ": "ê²°ì œ ìˆ˜ë‹¨(ì¹´ë“œ/ê³„ì¢Œì´ì²´ ë“±)ê³¼ ì˜¤ë¥˜ ë©”ì‹œì§€ê°€ ìžˆë‹¤ë©´ í•¨ê»˜ ì•Œë ¤ì£¼ì‹œë©´ í™•ì¸ì— ë„ì›€ì´ ë©ë‹ˆë‹¤.",
        "ìƒí’ˆ ë¬¸ì˜": "ì›í•˜ì‹œëŠ” **ì‚¬ì´ì¦ˆ/ìƒ‰ìƒ**ê³¼ ì‹ ì²´ ì¹˜ìˆ˜(ì˜ˆ: í‚¤/ì²´ì¤‘)ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë” ì •í™•ížˆ ì•ˆë‚´ë“œë¦´ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.",
        "íšŒì›/ë¡œê·¸ì¸": "ì‚¬ìš© ì¤‘ì¸ í™˜ê²½(ì•±/ì›¹, ê¸°ê¸°/ë¸Œë¼ìš°ì €)ê³¼ ë°œìƒ ì‹œì ì„ ì•Œë ¤ì£¼ì‹œë©´ ì›ì¸ íŒŒì•…ì— ë„ì›€ì´ ë©ë‹ˆë‹¤.",
        "ì¿ í°/í¬ì¸íŠ¸": "ì¿ í° ì½”ë“œ/í”„ë¡œëª¨ì…˜ëª…ê³¼ ìž¥ë°”êµ¬ë‹ˆ ê¸ˆì•¡, ì ìš© ë‹¨ê³„(ê²°ì œ ì „/í›„)ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ í™•ì¸ì— ë„ì›€ì´ ë©ë‹ˆë‹¤.",
        "ê¸°íƒ€(ìƒë‹´í•„ìš”)": "ì •í™•í•œ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤. **ì£¼ë¬¸ë²ˆí˜¸/ìƒí™©**ì„ ë‚¨ê²¨ì£¼ì‹œë©´ ìƒë‹´ìœ¼ë¡œ ë¹ ë¥´ê²Œ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
    }
    base += f"**ì¶”ê°€ í™•ì¸:** {followups.get(category, followups['ê¸°íƒ€(ìƒë‹´í•„ìš”)'])}\n\n"
    base += "_(ë°ëª¨ ë²„ì „: ì‹¤ì œ ìš´ì˜ ì •ì±…ì— ë§žì¶° ë¬¸êµ¬/ì¡°ê±´ì€ ì»¤ìŠ¤í„°ë§ˆì´ì§•ë©ë‹ˆë‹¤.)_"
    return base

# -----------------------------
# UI
# -----------------------------
st.title("ðŸ›’ ì‡¼í•‘ëª° CS ìžë™ ë¶„ë¥˜ ì±—ë´‡ (ë‚´ë¶€ ì—†ìœ¼ë©´ ì™¸ë¶€ RAG Fallback)")

left, right = st.columns([1.1, 0.9])

with left:
    st.subheader("1) ê³ ê° ë¬¸ì˜ ìž…ë ¥")
    user_text = st.text_area(
        "ì˜ˆ) 'ë°°ì†¡ì´ ì•„ì§ ì•ˆ ì™€ìš”', 'í™˜ë¶ˆ ì–¸ì œ ë¼ìš”?', 'ì¿ í°ì´ ì ìš©ì´ ì•ˆë¼ìš”' ë“±",
        height=140
    )

    st.subheader("2) ì„¤ì •")
    internal_threshold = st.slider("ë‚´ë¶€ KB ì‹ ë¢°ë„ ìž„ê³„ê°’(ë‚®ì„ìˆ˜ë¡ ë‚´ë¶€ë¥¼ ë” ìž˜ ì”€)", 0.05, 0.40, 0.18, 0.01)
    topk = st.slider("ê²€ìƒ‰ Top-K", 1, 5, 3, 1)
    show_debug = st.checkbox("ë””ë²„ê·¸ ì •ë³´ ë³´ê¸°(ì ìˆ˜/ê·¼ê±°)", value=True)

    run = st.button("ðŸš€ ì²˜ë¦¬í•˜ê¸°", type="primary", use_container_width=True)

with right:
    st.subheader("ì§€ì‹ë² ì´ìŠ¤ ìƒíƒœ")
    internal_df = load_kb("data/internal_kb.csv")
    external_df = load_kb("data/external_kb.csv")

    st.write(f"- ë‚´ë¶€ KB ë¬¸ì„œ ìˆ˜: **{len(internal_df)}**")
    st.write(f"- ì™¸ë¶€ KB ë¬¸ì„œ ìˆ˜: **{len(external_df)}**")

    with st.expander("ì™¸ë¶€ KB ë¯¸ë¦¬ë³´ê¸°"):
        st.dataframe(external_df[["id","category","title"]], use_container_width=True, hide_index=True)

# Build retrievers
internal_vec, internal_X, _ = build_retriever(internal_df)
external_vec, external_X, _ = build_retriever(external_df)

if run:
    if not user_text.strip():
        st.warning("ë¬¸ì˜ ë‚´ìš©ì„ ìž…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()

    st.divider()
    st.subheader("ê²°ê³¼")

    # 1) Classification
    pred_cat, conf, reasons = rule_classify(user_text)

    # 2) Retrieve from internal first
    internal_hits, _ = retrieve(internal_df, internal_vec, internal_X, user_text, topk=topk)
    use_fallback = should_fallback_internal(internal_hits, threshold=internal_threshold)

    source_type = "external" if use_fallback else "internal"
    if source_type == "internal":
        best = internal_hits.iloc[0]
    else:
        # external retrieval with category bias: filter same category first, if empty then global
        same_cat = external_df[external_df["category"].astype(str) == pred_cat]
        vec_cat, X_cat, _ = build_retriever(same_cat)
        ext_hits, _ = retrieve(same_cat, vec_cat, X_cat, user_text, topk=topk)
        if ext_hits.empty:
            ext_hits, _ = retrieve(external_df, external_vec, external_X, user_text, topk=topk)
        best = ext_hits.iloc[0] if not ext_hits.empty else pd.Series({"title":"ìƒë‹´ ì—°ê²° ì•ˆë‚´", "content":"ì •í™•í•œ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.", "score":0.0})

    # 3) Answer
    answer = generate_template_answer(
        category=pred_cat,
        user_text=user_text,
        source_title=str(best.get("title","")),
        source_content=str(best.get("content","")),
        source_type=source_type
    )

    colA, colB = st.columns([1,1])

    with colA:
        st.markdown("### âœ… ë¶„ë¥˜ ê²°ê³¼")
        st.markdown(f"- ì˜ˆì¸¡ ì¹´í…Œê³ ë¦¬: **{pred_cat}**")
        st.markdown(f"- ì¶”ì • ì‹ ë¢°ë„: **{conf:.2f}**")
        st.markdown(f"- ë¼ìš°íŒ…: **{('ì™¸ë¶€ RAG ì‚¬ìš©' if source_type=='external' else 'ë‚´ë¶€ KB ì‚¬ìš©')}**")

        if show_debug:
            st.markdown("#### ê·¼ê±°(ë””ë²„ê·¸)")
            for r in reasons:
                st.write(f"â€¢ {r}")
            if not internal_hits.empty:
                st.write("ë‚´ë¶€ Top-1 score:", float(internal_hits.iloc[0]["score"]))
            else:
                st.write("ë‚´ë¶€ Top-1 score: (ë‚´ë¶€ KB ì—†ìŒ)")

    with colB:
        st.markdown("### ðŸ’¬ ì±—ë´‡ ì‘ë‹µ")
        st.markdown(answer)

    if show_debug:
        st.divider()
        st.subheader("ê²€ìƒ‰ ê²°ê³¼(ë””ë²„ê·¸)")

        st.markdown("**ë‚´ë¶€ KB Top-K**")
        if internal_hits.empty:
            st.info("ë‚´ë¶€ KB ë¬¸ì„œê°€ ì—†ê±°ë‚˜ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.dataframe(internal_hits[["category","title","score"]], use_container_width=True, hide_index=True)

        st.markdown("**ì™¸ë¶€ KB Top-K**")
        ext_hits_all, _ = retrieve(external_df, external_vec, external_X, user_text, topk=topk)
        st.dataframe(ext_hits_all[["category","title","score"]], use_container_width=True, hide_index=True)

st.caption("ë°ëª¨ìš©: ì‹¤ì œ ìš´ì˜ ì •ì±…/ë¬¸êµ¬/ìž„ê³„ê°’/ì¹´í…Œê³ ë¦¬ëŠ” ì‡¼í•‘ëª°ì— ë§žì¶° ì»¤ìŠ¤í„°ë§ˆì´ì§•í•©ë‹ˆë‹¤.")
